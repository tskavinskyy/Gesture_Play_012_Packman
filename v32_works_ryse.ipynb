{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body Pose to play Ryze\n",
    "\n",
    "### https://www.google.com/logos/2010/pacman10-i.html\n",
    "\n",
    "#### https://www.youtube.com/watch?v=06TE_U21FK4\n",
    "#### https://www.youtube.com/watch?v=We1uB79Ci-w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preload libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from random import random\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import mediapipe as mp\n",
    "import joblib\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "\n",
    "import pywinauto\n",
    "import pyautogui\n",
    "from pywinauto.keyboard import send_keys, KeySequenceError\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'landmark'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "camera = cv2.VideoCapture(0)\n",
    "return_value, image = camera.read()\n",
    "\n",
    "image=np.real(camera.read()[1])\n",
    "###image = cv2.resize(image, (0,0), fx=0.2, fy=0.2) \n",
    "### testing the algorithm \n",
    "%time\n",
    "##image = all_images[i] \n",
    "tic = time.perf_counter()\n",
    "\n",
    "\n",
    "image_height, image_width, _ = image.shape\n",
    "with mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=0,\n",
    "    min_tracking_confidence=0.8,\n",
    "    min_detection_confidence=0.2) as pose:\n",
    "        \n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "points=results.pose_landmarks   \n",
    "xrow=[]\n",
    "for i in range(32):\n",
    "    xrow.append(points.landmark[i].x)\n",
    "    xrow.append(points.landmark[i].y)\n",
    "   \n",
    "annotated_image = image.copy()\n",
    "mp_drawing.draw_landmarks(\n",
    "        annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "plt.imshow(annotated_image)\n",
    "#cv2.imwrite('test.png', annotated_image)\n",
    "print(\"done in \"+str(time.perf_counter() - tic)+\" seconds\")\n",
    "cv2.imshow('image',annotated_image)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a dataset\n",
    "\n",
    "###https://github.com/nicknochnack/MediaPipePoseEstimation/blob/main/Media%20Pipe%20Pose%20Tutorial.ipynb\n",
    "###https://github.com/nicknochnack/Body-Language-Decoder/blob/main/Body%20Language%20Decoder%20Tutorial.ipynb\n",
    "\n",
    "# define a video capture object\n",
    "camera = cv2.VideoCapture(0)\n",
    "n=0\n",
    "xs=[]\n",
    "names=[]\n",
    "\n",
    "with mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=0,\n",
    "        min_tracking_confidence=0.8,\n",
    "        min_detection_confidence=0.2) as pose:\n",
    " \n",
    "    while(True):\n",
    "        \n",
    "        ### setting time\n",
    "        tic = time.perf_counter()\n",
    "        # Capture the video frame\n",
    "        # by frame\n",
    "\n",
    "        return_value, image = camera.read()\n",
    "        image=np.real(camera.read()[1])\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        #### Step through all the poses we want to capture and write the instuctions on the screen\n",
    "        if n<50:\n",
    "            record=False\n",
    "            cv2.putText(image, str(\"Get ready!!!!\"),tuple([120, 240]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        elif  n<75:\n",
    "            move=\"Nothing is next\"\n",
    "            record=False\n",
    "            cv2.putText(image, str(move+\"\" ),tuple([120, 340]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        elif  n<175:\n",
    "            move=\"4 Nothing\"\n",
    "            record=True\n",
    "            cv2.putText(image, str(move+\"\" ),tuple([120, 340]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        elif  n<200:\n",
    "            move=\"Up is next\"\n",
    "            record=False\n",
    "            cv2.putText(image, str(move+\"\" ),tuple([120, 340]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        elif  n<300:\n",
    "            move=\"0 Up\"\n",
    "            record=True\n",
    "            cv2.putText(image, str(move+\"\" ),tuple([120, 340]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        elif  n<325:\n",
    "            move=\"Left is next\"\n",
    "            record=False\n",
    "            cv2.putText(image, str(move+\"\" ),tuple([120, 340]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        elif  n<425:\n",
    "            move=\"1 Left\"\n",
    "            record=True\n",
    "            cv2.putText(image, str(move+\"\" ),tuple([120, 340]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        elif  n<450:\n",
    "            move=\"Down is next\"\n",
    "            record=False\n",
    "            cv2.putText(image, str(move+\"\" ),tuple([120, 340]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        elif  n<550:\n",
    "            move=\"2 Down\"\n",
    "            record=True\n",
    "            cv2.putText(image, str(move+\"\" ),tuple([120, 340]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        elif  n<575:\n",
    "            move=\"Right is next\"\n",
    "            record=False\n",
    "            cv2.putText(image, str(move+\"\" ),tuple([120, 340]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        elif  n<675:\n",
    "            move=\"3 Right\"\n",
    "            record=True\n",
    "            cv2.putText(image, str(move+\"\" ),tuple([120, 340]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                      \n",
    "        try:\n",
    "            #Drawing the image\n",
    "            mp_drawing.draw_landmarks( image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "            \n",
    "            ## storeing points\n",
    "            points=results.pose_landmarks   \n",
    "            xrow=[]\n",
    "            for i in range(32):\n",
    "                try:\n",
    "                    xrow.append(points.landmark[i].x)\n",
    "                    xrow.append(points.landmark[i].y)\n",
    "                    xrow.append(points.landmark[i].z)\n",
    "                except:\n",
    "                    xrow.append(0)\n",
    "                    xrow.append(0)\n",
    "                    xrow.append(0)\n",
    "            if record:                  \n",
    "                xs.append(xrow)\n",
    "                names.append(move)\n",
    "        except:\n",
    "            pass\n",
    "            #predicting the action\n",
    "\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', image)\n",
    "\n",
    "        # the 'q' button is set as the\n",
    "        # quitting button you may use any\n",
    "        # desired button of your choice\n",
    "        n=n+1\n",
    "        ##print (n)\n",
    "        \n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q'))or n>675:\n",
    "            break\n",
    "\n",
    "    # After the loop release the cap object\n",
    "    camera.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the sample of images into points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "done in 0.16065949999028817 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./random_forest.joblib']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create the modelq\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "y_train= encoder.fit_transform(names)\n",
    "### https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "# Create Decision Tree classifer object\n",
    "## train random forest instead\n",
    "clf=RandomForestClassifier(n_estimators=40, max_depth=5)\n",
    "clf = clf.fit(xs,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(xs)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, y_pred))\n",
    "\n",
    "print(\"done in \"+str(time.perf_counter() - tic)+\" seconds\")\n",
    "##https://mljar.com/blog/save-load-random-forest/\n",
    "joblib.dump(clf, \"./random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1]\n",
      "4 Nothing\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(y_pred[i])\n",
    "print(names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "\n",
    "#### Quit it with Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main Function\n",
    "####https://www.youtube.com/watch?v=06TE_U21FK4\n",
    "camera = cv2.VideoCapture(0)\n",
    "return_value, image = camera.read()\n",
    "w,l=pyautogui.size()  \n",
    "pyautogui.PAUSE = 0.051\n",
    "pyautogui.click(w/2, l/2)\n",
    "kp=\"unknown\"\n",
    "press_time=.2\n",
    "\n",
    "# define a video capture object\n",
    "camera = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=0,\n",
    "        min_tracking_confidence=0.8,\n",
    "        min_detection_confidence=0.2) as pose:\n",
    " \n",
    "    while(True):\n",
    "        ### setting time\n",
    "        tic = time.perf_counter()\n",
    "        # Capture the video frame\n",
    "        # by frame\n",
    "\n",
    "        return_value, image = camera.read()\n",
    "        image=np.real(camera.read()[1])\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        try:\n",
    "            #Drawing the image\n",
    "            ##mp_drawing.draw_landmarks( image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "            ## storeing points\n",
    "            points=results.pose_landmarks   \n",
    "            xrow=[]\n",
    "            for i in range(32):\n",
    "                try:\n",
    "                    xrow.append(points.landmark[i].x)\n",
    "                    xrow.append(points.landmark[i].y)\n",
    "                    xrow.append(points.landmark[i].z)\n",
    "                except:\n",
    "                    xrow.append(0)\n",
    "                    xrow.append(0)\n",
    "                    xrow.append(0)\n",
    "            #predicting the action\n",
    "            xs_test=[]\n",
    "            xs_test.append(xrow)\n",
    "            y_pred_test = clf.predict(xs_test)\n",
    "            #### pressing the button based on the acction\n",
    "            i=0\n",
    "\n",
    "\n",
    "            if (y_pred_test[i][4]==1):\n",
    "                    ##send_keys(\"{up}\")\n",
    "                    k=\"nothing\"\n",
    "                    kp=\"nothing\"\n",
    "            elif (y_pred_test[i][0]==1):\n",
    "                    k=\"up\"\n",
    "                    kp=\"up\"\n",
    "                    send_keys('{w down}')\n",
    "                    time.sleep(press_time*3)\n",
    "                    send_keys(\"{w up}\")\n",
    "            elif (y_pred_test[i][1]==1):\n",
    "                    k=\"left\"\n",
    "                    kp=\"left\"\n",
    "                    send_keys('{a down}')\n",
    "                    time.sleep(press_time)\n",
    "                    send_keys(\"{a up}\")\n",
    "            elif (y_pred_test[i][2]==1):\n",
    "                    k=\"down\"\n",
    "                    kp=\"down\"\n",
    "                    send_keys('{s down}')\n",
    "                    time.sleep(press_time)\n",
    "                    send_keys(\"{s up}\")\n",
    "            elif (y_pred_test[i][3]==1):\n",
    "                    k=\"right\"\n",
    "                    kp=\"right\"       \n",
    "                    send_keys('{d down}')\n",
    "                    time.sleep(press_time)\n",
    "                    send_keys(\"{d up}\")\n",
    "            else:\n",
    "            \n",
    "                    k=\"unknown\"\n",
    "                    kp=\"unknown\"\n",
    "                    ##send_keys(\"{up}\")\n",
    "\n",
    "            result=( \"said \"+k+\"| in \"+str(round(time.perf_counter() - tic,2)) )\n",
    "            ##print( result)\n",
    "        except:\n",
    "            pass\n",
    "            #predicting the action\n",
    "\n",
    "\n",
    "        # Display the resulting frame\n",
    "        try:\n",
    "            ##cv2.putText(image, str(k),tuple([120, 240]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            1+1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        cv2.imshow('frame', image)\n",
    "\n",
    "        # the 'q' button is set as the\n",
    "        # quitting button you may use any\n",
    "        # desired button of your choice\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # After the loop release the cap object\n",
    "    camera.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up\n"
     ]
    }
   ],
   "source": [
    "time.sleep(2.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
